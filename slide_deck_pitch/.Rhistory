?splitTextGrob
?gridExtra
?grid.draw
grid.newpage()
grid.draw(text)
?grid.draw
linesGrob(text)
?grob
grob(text)
g<-grob(text)
g
grid.draw(g)
grid.newpage()
grid.draw(g)
?as.grob
as.grob(text)
grid.grob(text)
grob(text)
grid.draw(text)
text
install.packages("gridExtra")
library(gridExtra)
grid.arrage(text)
grid.arrange(text)
grid.arrange(grob(text)
)
grid.arrange(splitTextGrob(text)
)
grid.newpage()
text
grid.arrange(splitTextGrob(text))
grid.newpage()
grid.arrange(grob(text))
grid.newpage()
grid.draw(splitTextGrob(text))
grid.newpage()
grid.draw(splitTextGrob(text, '', '')
)
text
grid.newpage()
text = paste("No Whiskeys Found", "To Match Your Criteria")
grid.draw(splitTextGrob(text))
runApp()
runApp()
runApp()
xyplot(x=0, y=0,
main = 'No Whiskey Found To Match Your Criteria'
xyplot(x=0, y=0,
main = 'No Whiskey Found To Match Your Criteria'-???>>>
xyplot(x=0, y=0,
main = 'No Whiskey Found To Match Your Criteria')
?lattice
?xyplot
barchart(x=0)
dotplot(x=0)
dotplot(x=0, main = 'No WHiskey')
xyplot(x=0, y=0)
lattice()
plot(c(0, 1), c(0, 1), ann = F, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')
text(x = 0.5, y = 0.5, paste("The following is text that'll appear in a plot window.\n",
"As you can see, it's in the plot window\n",
"One might imagine useful informaiton here"),
cex = 1.6, col = "black")
runApp()
runApp()
plot(c(0, 1), c(0, 1), ann = F, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')
text('No WHiskey')
plot(c(0, 1), c(0, 1), ann = F, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')
text(x=0.5,y-0.5,'No WHiskey',cex=1.6,col='black')
text(x=0.5,y=0.5,'No WHiskey',cex=1.6,col='black')
runApp()
runApp()
deployApp()
plot(c(0, 1), c(0, 1), ann = F, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n', main = 'asdf')
plot(c(0, 1), c(0, 1), ann = T, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n', main = 'asdf')
plot(c(0, 1), c(0, 1), ann = T, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n', main = 'asdf', ylab = '', xlab = '')
runApp()
plot(c(0, 1), c(0, 1), ann = F,
bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n',
xlab = '', ylab = '',
main = 'No Whiskeys Found to Match Your Criteria'
)
runApp()
deployApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
deployApp()
runApp()
?column
?includeMarkdown
library(markdown)
runApp()
deployApp()
runApp()
runApp()
library(slidify)
author("whiskey_pitch")
body<-0; notes<-c('Smoky', 'Spicy')
WhiskeyMatches<-findWhiskeys(body, notes)
WhiskeyMatches
publish(title="DevelopingDataProducts", index.Rmd, host='rpubs')
publish(title="DevelopingDataProducts", 'index.Rmd', host='rpubs')
publish(title="DevelopingDataProducts", 'index.md', host='rpubs')
publish(title="DevelopingDataProducts", 'index.html', host='rpubs')
publish(user = "drsaltiel", repo = "CourseraDevelopingDataProducts")
publish(user = "drsaltiel", repo = "drsaltiel.github.io")
publish(user = "drsaltiel", repo = "CourseraDevelopingDataProducts_Slidify")
library(datasets); data(mtcars)
plot(mtcars)
plot(mpg~am, data=mtcars)
boxplot(mpg~am, data=mtcars)
install.packages('swirl')
library(swirl)
ls()
swirl()
plot(chile~parent,galton)
plot(child~parent,galton)
plot(jitter(child,4)~parent,galton)
regrline<-lm(child~parent, galton)
abline(regrline, lwd=3,col='red')
summary(regrline)
lem(mpg~transmission, mtcars)
lm(mpg~transmission, mtcars)
View(mtcars)
lm(mpg~am, mtcars)
sumary(lm(mpg~am, mtcars))
summary(lm(mpg~am, mtcars))
?lm
plot(mpg~am, data=mtcars, xlab = 'Transmission', ylab = 'mpg')
abline(linearMod)
linearMod<-lm(mpg~am, mtcars)
abline(linearMod)
plot(mpg~am, data=mtcars, xlab = 'Transmission', ylab = 'mpg', xlim = c(-1,2))
abline(linearMod)
plot(mpg~am, data=mtcars, xlab = 'Transmission', ylab = 'mpg', xlim = c(-0.,1.5))
abline(linearMod)
plot(mpg~am, data=mtcars, xlab = 'Transmission', ylab = 'mpg', xlim = c(-0.5,1.5))
abline(linearMod)
?I
resid(linearMod)
predict(linearMod)
max(abs(resid(linearMod)-(mtcars$mpg-predict(linearMod))))
plot(residual)
plot(residuals)
residuals
linearMod<-lm(mpg~am, mtcars)
residuals<-resid(linearMod)
predicted<-predict(linearMod)
plot residuals
plot(residuals)
summary(linearMod)$sigma
?cov
cov(mtcars)
cov2cor(cov(mtcars))
plot(mtcars)
?mtcars
a<-c(140,138,150,148,135)
b<-c(132,135,151,146,130)
?t.test
t.test(a,b,paired=TRUE, alternative = 'two.sided')
1100+c(_1,1)*qt()
?qt
1100+c(-1,1)*qt(.975,8)*30/3
?poisson.test
poisson.test(10, 1787, 'less')
poisson.test(10, 1787, alternative = 'less')
poisson.test(10, 1787, r=1/100, alternative = 'less')
?binom.test
binom.test(3,4)
?t.test
-3+c(-1,1)*qt(.975,8)*1.5/3
1+c(-1,1)*qt(.975,8)*1.8/3
?at
?qt
qt(.965,8)
?t.test
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train
summary(vowel.train)
set.seed(33833)
rfmod<-train(y~., data=vowel.train, method = 'rf')
gbmmod<-train(y~.,data=vowel.train,method='gbm')
predict(vowel.test, rfmod)
rfmod
?predict
predict(rfmod, vowel.test)
confusionMatrix(predict(rfmod, vowel.test, reference=vowel.test$y))
confusionMatrix(predict(rfmod, vowel.test), reference=vowel.test$y)
vowel.test$y
confusionMatrix(predict(gbmmod, vowel.test), reference=vowel.test$y)
predict(gbmmod, vowel.test)
?factor
fitrf<-train(factor(y,levels=levs)~., moethod='gbm', data=vowel.train)
fitrf<-train(factor(y,levels=levels(vowel.train$y))~., moethod='gbm', data=vowel.train)
levels(vowel.train$y)
vowel.train$y
factor(vowel.train$y)
fitrf<-train(factor(y)~., moethod='gbm', data=vowel.train)
fitrf<-train(factor(y)~., moethod='rf', data=vowel.train)
fitgbm<-train(factor(y)~., moethod='gbm', data=vowel.train)
predict(fitgbm, vowel.test)
confusionMatrix(predict(fitgbm, vowel.test), reference=vowel.test$y)
confusionMatrix(predict(fitgbm, vowel.test), reference=vowel.test$y)$Accuracy
?confusionMatrix
confusionMatrix(predict(fitgbm, vowel.test), reference=vowel.test$y)$accuracy
confusionMatrix(predict(fitgbm, vowel.test), reference=vowel.test$y)$positive
confusionMatrix(predict(fitgbm, vowel.test), reference=vowel.test$y)$overall
confusionMatrix(predict(fitrf, vowel.test), reference=vowel.test$y)$overall
predict(fitrf, vowel.test) == predict(fitgbm, vowel.test)
confusionMatrix(predict(fitrf, vowel.test), reference=vowel.test$y)
confusionMatrix(predict(fitgbm, vowel.test), reference=vowel.test$y)$overall
confusionMatrix(predict(fitrf, vowel.test), reference=vowel.test$y)$overall
predDF<-dataframe(predict(fitrf, vowel.train), predict(fitgbm, vowel.train), vowel.train$y)
predDF<-data.frame(predict(fitrf, vowel.train), predict(fitgbm, vowel.train), vowel.train$y)
fitcomb<-train(y~., method='gam', data=predDF)
predDF
fitcomb<-train(factor(y)~., method='gam', data=predDF)
fitcomb<-train(factor(vowel.train.y)~., method='gam', data=predDF)
fitcomb
predict(fitcomb, vowel.test)
colnames(predDF
)
?colnames
colnames(predDF)<- c(rf, gbm, y)
colnames(predDF)<- c('rf', 'gbm', 'y')
summary(predDF)
fitcomb<-train(factor(y)~., method='gam', data=predDF)
predict(fitcomb, vowel.test)
summary(vowel.test)
fitcomb
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
summary(training)
rfAlz<-train(diagnosis~., data=training, method='rf')
gbmAlz<-train(diagnosis~., data=training, method='gbm')
ldaAlz<-train(diagnosis~., data=training, method='lda')
rfAlzP<-predict(rfAlz, testing)
gbmAlzP<-predict(gbmAlz, testing)
ldaAlzP<-predict(ldaAlz, testing)
rfAlzP
confusionMatrix(rfAlzp, testing$diagnosis)
confusionMatrix(rfAlzP, testing$diagnosis)
confusionMatrix(rfAlzP, testing$diagnosis)$summary
?confusionMatrix
confusionMatrix(rfAlzP, testing$diagnosis)$overall
confusionMatrix(gbmAlzP, testing$diagnosis)$overall
confusionMatrix(ldaAlzP, testing$diagnosis)$overall
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
?plot.enet
?cv.glmnet
plot.enet(modFit$finalModel, xvar = "penalty", use.color = TRUE)
library(elasticnet)
install.packages("elasticnet")
?plot.enet
library(elasticnet)
?plot.enet
plot(x, xvar = c("fraction", "penalty", "L1norm", "step"), use.color = FALSE, ...)
plot.enet(modFit$finalModel, xvar = "penalty", use.color = TRUE)
summary(testing)
train(CompressiveStrength~., method = 'lasso', data = training)
?train
?trControl
?trainControl
?enet
enet(CompressiveStrength~.)
enet(CompressiveStrength~., lambda = 0)
enet(training, training$compressiveStrength)
enet(as.matrix(training), training$compressiveStrength)
as.matrix(training)
summary(training)
enet(as.matrix(training[1:8]), training$compressiveStrength)
training[1:8]
enet(as.matrix(training[1:8]), training$compressiveStrength, lambda=0)
a<-enet(as.matrix(training[1:8]), training$compressiveStrength, lambda=0)
as.matrix(training[1:8])
a<-enet(as.matrix(training[1:8]), training$compressiveStrength, lambda=0)
set.seed(3523)
m<-train(CompressiveStrength~., data = training, method = 'lasso')
plot.enet(m, xvar = 'penalty', use.color = TRUE)
m
m$finalModel
plot.enet(m$finalModel, xvar = 'penalty', use.color = TRUE)
attributes(m$finalModel)
m$finalModel$names
m$finalModel$enet
m$finalModel$names('call')
m$finalModel$names$call
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("lubridate")
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
url<-'https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv'
dat<-read.csv(url)
url<-'http://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv'
dat<-read.csv(url)
summary(dat)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
?bats
library(forcast)
library(forecast)
install.packages("forecast")
library(forecast)
?bats
bats(training)
bats(tstrain)
bats<-bats(tstrain)
predict(bats, testing)
?forecast
forecast(bats, testing)
forecast(bats)
accuracy(forecast(bats, testing$visitsTumblr))
testing
forecast(bats, h = length(testing$visitsTumblr))
fcast<-forecast(bats, h = length(testing$visitsTumblr))
accuracy(fcast, testing$visitsTumblr)
?accuracy
attributes(accuracy(fcast, testing$visitsTumblr))
summary(fcast)
accuracy(fcast, testing$visitsTumblr)
fcast$lower[,2]
fcast$lower
length(testing[testing$visitsTumblr > fcast$lower[,2] | testing$visitsTumblr < fcast$upper[,2]])
length(subset(testing, testing$visitsTumblr > fcast$lower[,2] | testing$visitsTumblr < fcast$upper[,2]))
length(subset(testing, testing$visitsTumblr > fcast$lower[,2] | testing$visitsTumblr < fcast$upper[,2])[,1])
length(subset(testing, testing$visitsTumblr > fcast$lower[,2] | testing$visitsTumblr < fcast$upper[,2])[,1])/length(testing$visitsTumblr)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
summary(training)
?svm
svm(CompressiveStrength~.)
svm(CompressiveStrength~., data = training)
s<-svm(CompressiveStrength~., data = training)
predict(s, testing)
accuracy(predict(s, testing), testing$CompressiveStrength)
set.seed(33833)
rfmod<-train(y~., data=vowel.train, method = 'rf')
accuracy(predict(rfmod, vowel.test), vowel.test$Y)
accuracy(predict(rfmod, vowel.test), vowel.test$y)
sum(predict(rfmod, vowel.test) == vowel.test$y) / length(vowel.test$y)
sum(predict(rfmod, vowel.test) == vowel.test$y)
predict(rfmod, vowel.test)
set.seed(33833)
rfmod<-train(factor(y)~., data=vowel.train, method = 'rf')
sum(predict(rfmod, vowel.test) == vowel.test$y) / length(vowel.test$y)
gbmmod<-train(factor(y)~., data=vowel.train, method = 'gbm')
sum(predict(rfmod, vowel.test) == vowel.test$y) / length(vowel.test$y)
sum(predict(gbmmod, vowel.test) == vowel.test$y) / length(vowel.test$y)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
bats<-bats(tstrain)
pbats<-predict(bats, testing)
pbats<-predict(bats, testing$visitsTumblr)
bats
?predict
forecast(bats, testing$visitsTumblr)
?ts
tstest = ts(testing$visitsTumblr)
forecast(bats, tstest)
predict(bats, tstest)
?predict
forecast(bats, h = length(testing$visitsTumblr))
fcast<- forecast(bats, h = length(testing$visitsTumblr))
colnames(fcast)
attributes(fcast)
mean(fcast$upper[,2])
tstest[tstest > fcast$upper[,2]]
tstest[tstest < fcast$lower[,2]]
9/length(tstest)
1 - 9/length(tstest)
t.test
?t.test
t.test(-3, 1, alternative = "two.sided", var.equal = T)
?pt
pt(-3, 8)
pt(-3/1.5, 8)
?z.test
?pvalue
?Pvalue
?p.value
pt(44/12, 287)
pt(42.04/12, 287)
qnorm(.975, 287)
?qnorm
qnorm(.975)*12/sqrt(288)
2*(1-pnorm(44-42.04, 44, sd = 12/sqrt(288)))
pnorm(44-42.04, 44, sd = 12/sqrt(288))
pnorm(44-42.04, mean = 44, sd = 12/sqrt(288))
pnorm(44-42.04, mean = 44, sd = 12
)
pnorm(42.04, mean = 44, sd = 12/sqrt(288))
pt(.01/.04, 139)
pt(.01/.04, 179)
pt(.01/.04, 119)
?power.t.test
power.t.test(100, 0.01, sd = 0.04, type = 'one.sample', alternative = 'one.sided')
power.t.test(9, delta = 4, sd = 1.65, type = 'two.sample', alternative = 'two.sided')
power.t.test(120, 0.01, sd = 0.04, type = 'one.sample', alternative = 'one.sided')
power.t.test(140, 0.01, sd = 0.04, type = 'one.sample', alternative = 'one.sided')
pwer.t.test(288, 1.96, sd = 12, type = "two.sample", alternative = "two.sided")
power.t.test(288, 1.96, sd = 12, type = "two.sample", alternative = "two.sided")
pt(.196/12,287)
z<-0.196/(12/288)
z
pnorm(-z)
z<-0.196/(12/sqrt(288))
z
pnorm(-z)
?t.test
pt(.196/12, 288)
?qnorm
?qt
42.04+c(-1,1)*qt(.975, 287)*12/sqrt(288)
42.04+c(-1,1)*qt(.995, 287)*12/sqrt(288)
42.04+c(-1,1)*qt(.999, 287)*12/sqrt(288)
42.04+c(-1,1)*qt(.9975, 287)*12/sqrt(288)
?binom.test
binom.test(3, 4, alternative'one.sided')
binom.test(3, 4, alternative = 'one.sided')
binom.test(3, 4, alternative = 'less')
binom.test(3, 4, alternative = 'greater')
binom.test(3, 4, alternative = 'two.sided')
power.t.test(9, 4, sd = 65, type = "two.sample", alternative = "two.sided")
?t.test
t.test(9, 4, sd = 65, type = "two.sample", alternative = "two.sided")
power.t.test(9, 4, sd = 65, type = "two.sample", alternative = "two.sided")$p.value
?power.t.test
-3+c(-1,1)*qt(.975, 8)*1/3
1+c(-1,1)*qt(.975, 8)*1.8/3
-3+c(-1,1)*qt(.975, 8)*1.5/3
-3+c(-1,1)*qt(.995, 8)*1.5/3
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
?lm
lm(data=x, weights = w)
?leastsquared
x*w
mean(x*w)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(x~y -1)
lm(y~x -1)
data(mtcars)
lm(mpg~wt, data=mtcars)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
x-mean(x)
var(x-mean(x))
(x-mean(x))/var(x)
mean((x-mean(x))/var(x))
var((x-mean(x))/var(x))
mean((x-mean(x))/sd(x))
var((x-mean(x))/sd(x))
mean((x-mean(x))/sd(x))
(x-mean(x))/sd(x)
lm(x~y)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(x~y)
lm(y~x)
x <- c(0.18, -1.54, 0.42, 0.95
)
lsfit(x, weight=w)
?lsfit
lsfit(x, wt=w)
mean(x*y)
x
y
mean(x*w)
x
w
x*w
